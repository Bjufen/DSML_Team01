{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:44.971678Z",
     "start_time": "2023-07-22T13:11:44.862400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy import distance\n",
    "import folium\n",
    "import datetime as dt\n",
    "\n",
    "csv_file = '../Data_Cleanup/outCSV/Station_ID_with_AvgIdleDaytimesDays_and_lonlat.csv'\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:45.152577Z",
     "start_time": "2023-07-22T13:11:44.873931Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"idle_time\"] = pd.to_timedelta(df[\"idle_time\"])\n",
    "\n",
    "#####################################Important\n",
    "sorted_df = df.sort_values(by=\"idle_time\", ascending=False)\n",
    "sorted_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the station 4403 has an unnormal idle_time, my first idea would be to filter the original data by the station id and plot the idle_time of each trip against the start time of the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:48.358809Z",
     "start_time": "2023-07-22T13:11:48.221785Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################Important\n",
    "full_data = pd.read_csv(\"../Data_Cleanup/outCSV/Metro_Set_DayAndDayTimes.csv\", index_col=0)\n",
    "\n",
    "# Filter the rows for the station with ID 4403\n",
    "station_data = full_data[(full_data['start_station_id'] == 4403) | (full_data['end_station_id'] == 4403)]\n",
    "\n",
    "# Convert the idle_time column to numeric values in days\n",
    "station_data['idle_time'] = pd.to_timedelta(station_data['idle_time']).dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    "# Create a histogram of idle_time values\n",
    "plt.hist(station_data['idle_time'], bins=20)\n",
    "plt.xlabel('Idle Time (days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Idle Time for Station 4403')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Histogramm we can see that we have around 40 rows that has more than 1000 days in idle time.\n",
    "\n",
    "Lets take a better look at those 40 trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:48.698673Z",
     "start_time": "2023-07-22T13:11:48.365329Z"
    }
   },
   "outputs": [],
   "source": [
    "#########Important\n",
    "\n",
    "station_data = full_data[(full_data['start_station_id'] == 4403) | (full_data['end_station_id'] == 4403)]\n",
    "station_data['start_time'] = pd.to_datetime(station_data[\"start_time\"])\n",
    "station_data['end_time'] = pd.to_datetime(station_data[\"end_time\"])\n",
    "\n",
    "# Convert 'idle_time' column to Timedelta\n",
    "station_data['idle_time'] = pd.to_timedelta(station_data['idle_time'])\n",
    "# Filter the rows for the station with ID 4403 and idle_time over 1000 days\n",
    "long_idle_trips = station_data[station_data[\"idle_time\"] > pd.Timedelta(days=1000)]\n",
    "# Sort the trips by end_time in ascending order\n",
    "long_idle_trips = long_idle_trips.sort_values('end_time')\n",
    "\n",
    "# Initialize an empty DataFrame to store the comparison results\n",
    "comparison_results = pd.DataFrame(columns=['Trip', 'End Time', 'Next Start Time'])\n",
    "\n",
    "# Iterate over the rows of the long_idle_trips DataFrame\n",
    "for index, row in long_idle_trips.iterrows():\n",
    "    end_time = row['end_time']\n",
    "    for index, row in station_data.iterrows():\n",
    "        if row[\"start_time\"] > end_time:\n",
    "            next_start_time = row[\"start_time\"]\n",
    "    comparison_results = pd.concat([comparison_results, pd.DataFrame({'Trip': [index], 'End Time': [end_time], 'Next Start Time': [next_start_time]})], ignore_index=True)\n",
    "\n",
    "# Print the comparison results\n",
    "print(comparison_results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems tht there has been a huge break in the usage in this station, let try to find it.\n",
    "\n",
    "Looking at the data we can see that no one used the station between 2020-02-23 15:09:00 and 2022-12-04 14:54:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:48.904882Z",
     "start_time": "2023-07-22T13:11:48.697677Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_df['end_station_lat'] = sorted_df['end_station_lat'].str[1:-1].astype(np.float64)\n",
    "sorted_df['end_station_lon'] = sorted_df['end_station_lon'].str[1:-1].astype(np.float64)\n",
    "\n",
    "\n",
    "\n",
    "# Filter the sorted_df to exclude outliers with more than 30 days of idle time\n",
    "filtered_df = sorted_df[sorted_df['idle_time'] <= pd.Timedelta(days=30)]\n",
    "\n",
    "# Take the top 20 stations with the highest idle time\n",
    "top_20_stations = filtered_df.head(20)\n",
    "\n",
    "# Convert the end_station_id to string\n",
    "top_20_stations[\"end_station_id\"] = top_20_stations[\"end_station_id\"].astype(str)\n",
    "\n",
    "# Plot the vertical bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_20_stations[\"end_station_id\"], top_20_stations[\"idle_time\"].dt.days)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "plt.title(\"Top 20 Stations with Highest Idle Time\")\n",
    "plt.xlabel(\"Station ID\")\n",
    "plt.ylabel(\"Idle Time (Days)\")\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:49.200401Z",
     "start_time": "2023-07-22T13:11:48.907804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take the top 10 stations with the highest idle time\n",
    "bottom_20_stations = filtered_df.tail(20)\n",
    "\n",
    "# Convert the end_station_id to string\n",
    "bottom_20_stations[\"end_station_id\"] = bottom_20_stations[\"end_station_id\"].astype(str)\n",
    "\n",
    "# Plot the vertical bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bottom_20_stations[\"end_station_id\"], bottom_20_stations[\"idle_time\"].dt.total_seconds()/60)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "plt.title(\"Bottom 20 Stations with Lowest Idle Time\")\n",
    "plt.xlabel(\"Station ID\")\n",
    "plt.ylabel(\"Idle Time (Minutes)\")\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To approach the problem methodically. We will sort our data by the average idle_time of the stations. We wil split our data into two halves (top_50_percent and bottom_50_percent). We will look for the average idle_time for each half. the candidate stations (to be either closed or expanded) will be either above the top_avg or below the bottom_avg respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 393 Stations. We will divide them into two halves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:49.766782Z",
     "start_time": "2023-07-22T13:11:49.654690Z"
    }
   },
   "outputs": [],
   "source": [
    "top_50_percent = filtered_df.head(197)\n",
    "bottom_50_percent = filtered_df.tail(196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:49.766782Z",
     "start_time": "2023-07-22T13:11:49.697488Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "avg_idle_time_top_50 = top_50_percent[\"idle_time\"].mean()\n",
    "avg_idle_time_bottom_50 = bottom_50_percent[\"idle_time\"].mean()\n",
    "\n",
    "#Our Candidates in the top half\n",
    "over_top_avg_df = top_50_percent[top_50_percent[\"idle_time\"] >= avg_idle_time_top_50]\n",
    "\n",
    "#Our Candidates in the bottom half\n",
    "under_bottom_avg_df = bottom_50_percent[bottom_50_percent[\"idle_time\"] <= avg_idle_time_bottom_50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further filter the candidates we decides to look for the neighboring stations of the candidates. The Radius a station has to be in is 500 m to considered a neighbor. We will take the average of the idle_time of the neighboring stations to see how our candidates is performing regarding its neighbors. if a candidate from the top half has a higher idle_time than the avg_neighbor_idle_time and has at least 2 neighbor, it should be closed. On the other hand if a candidate from the bottom half has a lower idle_time than the avg_neighbor_idle_time and has less than 2 neighbours, it should be expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:12:00.668731Z",
     "start_time": "2023-07-22T13:11:50.479300Z"
    }
   },
   "outputs": [],
   "source": [
    "over_top_avg_df[\"neighboring_stations\"] = None\n",
    "over_top_avg_df[\"avg_neighbor_idle_time\"] = None\n",
    "for i, row in over_top_avg_df.iterrows():\n",
    "    station_id = row['end_station_id']\n",
    "    lat = row['end_station_lat']\n",
    "    lon = row['end_station_lon']\n",
    "    center_coords = (lat, lon)\n",
    "    neighbor_idle_time_sum = pd.Timedelta(0)\n",
    "\n",
    "\n",
    "    neighboring_stations = []\n",
    "    for index, sorted_row in filtered_df.iterrows():\n",
    "        station_coords = (sorted_row['end_station_lat'], sorted_row['end_station_lon'])\n",
    "        dist = distance.distance(center_coords, station_coords).meters\n",
    "        \n",
    "        if dist <= 500:\n",
    "            neighboring_stations.append(sorted_row[\"end_station_id\"])\n",
    "            neighbor_idle_time_sum += pd.Timedelta(sorted_row[\"idle_time\"])\n",
    "    over_top_avg_df.at[i, \"neighboring_stations\"] = neighboring_stations\n",
    "    over_top_avg_df.at[i, \"avg_neighbor_idle_time\"] = neighbor_idle_time_sum / len(neighboring_stations)\n",
    "\n",
    "\n",
    "under_bottom_avg_df[\"neighboring_stations\"] = None\n",
    "under_bottom_avg_df[\"avg_neighbor_idle_time\"] = None\n",
    "\n",
    "for i, row in under_bottom_avg_df.iterrows():\n",
    "    station_id = row['end_station_id']\n",
    "    lat = row['end_station_lat']\n",
    "    lon = row['end_station_lon']\n",
    "    center_coords = (lat, lon)\n",
    "    neighbor_idle_time_sum = pd.Timedelta(0)\n",
    "\n",
    "\n",
    "    neighboring_stations = []\n",
    "    for index, sorted_row in filtered_df.iterrows():\n",
    "        station_coords = (sorted_row['end_station_lat'], sorted_row['end_station_lon'])\n",
    "        dist = distance.distance(center_coords, station_coords).meters\n",
    "        \n",
    "        if dist <= 500:\n",
    "            neighboring_stations.append(sorted_row[\"end_station_id\"])\n",
    "            neighbor_idle_time_sum += pd.Timedelta(sorted_row[\"idle_time\"])\n",
    "\n",
    "\n",
    "    under_bottom_avg_df.at[i, \"neighboring_stations\"] = neighboring_stations\n",
    "    under_bottom_avg_df.at[i, \"avg_neighbor_idle_time\"] = neighbor_idle_time_sum / len(neighboring_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_removed = []\n",
    "for i, zeile in over_top_avg_df.iterrows():\n",
    "        if zeile[\"idle_time\"] > zeile[\"avg_neighbor_idle_time\"] and len(zeile[\"neighboring_stations\"]) > 2:\n",
    "            to_be_removed.append(zeile[\"end_station_id\"])\n",
    "\n",
    "\n",
    "to_be_expanded = []\n",
    "for i, zeile in under_bottom_avg_df.iterrows():\n",
    "        if zeile[\"idle_time\"] < zeile[\"avg_neighbor_idle_time\"] and len(zeile[\"neighboring_stations\"]) < 3:\n",
    "            to_be_expanded.append(zeile[\"end_station_id\"])\n",
    "\n",
    "\n",
    "\n",
    "print(to_be_removed)\n",
    "print(len(to_be_removed))\n",
    "print(to_be_expanded)\n",
    "print(len(to_be_expanded))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That would be the list of the Stations that need to either closed or expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latitude and Longitude coordinates of Los Angeles\n",
    "la_coordinates = (34.0522, -118.2437)\n",
    "\n",
    "# Create a folium map centered on Los Angeles\n",
    "map_la = folium.Map(location=la_coordinates, zoom_start=11)\n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    station_id = row['end_station_id']\n",
    "    lat = row['end_station_lat']\n",
    "    lon = row['end_station_lon']\n",
    "    \n",
    "    \n",
    "    if station_id in to_be_expanded:\n",
    "        folium.Marker(location=[lat, lon], tooltip=[str(station_id)], icon = folium.Icon(color=\"green\")).add_to(map_la)\n",
    "    elif station_id in to_be_removed:\n",
    "        folium.Marker(location=[lat, lon], tooltip=[str(station_id)], icon = folium.Icon(color=\"red\")).add_to(map_la)\n",
    "    else:\n",
    "        folium.Marker(location=[lat, lon], tooltip=[str(station_id)]).add_to(map_la)\n",
    "map_la"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
