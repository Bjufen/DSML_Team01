{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-22T21:50:27.102055Z",
     "end_time": "2023-07-22T21:50:27.103063Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy import distance\n",
    "import folium\n",
    "import datetime as dt\n",
    "\n",
    "csv_file = '../Data_Cleanup/outCSV/Station_ID_with_AvgIdleDaytimesDays_and_lonlat.csv'\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-22T21:50:27.169850Z",
     "end_time": "2023-07-22T21:50:27.169850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     end_station_id                   idle_time  morgens  vormittags  mittags  \\\n215            4403 293 days 23:18:23.586206896       62         123       64   \n156            4321  16 days 08:02:23.571428571       17          16       16   \n31             3039  16 days 06:44:38.608695652       71          79       60   \n191            4363  13 days 15:34:22.466666666       11          12       13   \n239            4432  10 days 23:02:06.598639455      110         104       98   \n\n     nachmittags  abends  nachts  monday  tuesday  wednesday  thursday  \\\n215           43      43      43      43       43         43        42   \n156           11       9      12       5        6          8         5   \n31            34      34      34      34       34         34        34   \n191           10      11      12       8        9         10        12   \n239           81      66      99      46       56         64        51   \n\n     friday  saturday  sunday end_station_lat end_station_lon  \n215      42        42     136     [33.943359]   [-118.248238]  \n156       7         4       4     [34.031399]   [-118.453629]  \n31       34        34     113     [34.024479]   [-118.393867]  \n191       7         6       6      [34.03046]   [-118.389099]  \n239      63        60      50     [34.139568]   [-118.362251]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>end_station_id</th>\n      <th>idle_time</th>\n      <th>morgens</th>\n      <th>vormittags</th>\n      <th>mittags</th>\n      <th>nachmittags</th>\n      <th>abends</th>\n      <th>nachts</th>\n      <th>monday</th>\n      <th>tuesday</th>\n      <th>wednesday</th>\n      <th>thursday</th>\n      <th>friday</th>\n      <th>saturday</th>\n      <th>sunday</th>\n      <th>end_station_lat</th>\n      <th>end_station_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>215</th>\n      <td>4403</td>\n      <td>293 days 23:18:23.586206896</td>\n      <td>62</td>\n      <td>123</td>\n      <td>64</td>\n      <td>43</td>\n      <td>43</td>\n      <td>43</td>\n      <td>43</td>\n      <td>43</td>\n      <td>43</td>\n      <td>42</td>\n      <td>42</td>\n      <td>42</td>\n      <td>136</td>\n      <td>[33.943359]</td>\n      <td>[-118.248238]</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>4321</td>\n      <td>16 days 08:02:23.571428571</td>\n      <td>17</td>\n      <td>16</td>\n      <td>16</td>\n      <td>11</td>\n      <td>9</td>\n      <td>12</td>\n      <td>5</td>\n      <td>6</td>\n      <td>8</td>\n      <td>5</td>\n      <td>7</td>\n      <td>4</td>\n      <td>4</td>\n      <td>[34.031399]</td>\n      <td>[-118.453629]</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>3039</td>\n      <td>16 days 06:44:38.608695652</td>\n      <td>71</td>\n      <td>79</td>\n      <td>60</td>\n      <td>34</td>\n      <td>34</td>\n      <td>34</td>\n      <td>34</td>\n      <td>34</td>\n      <td>34</td>\n      <td>34</td>\n      <td>34</td>\n      <td>34</td>\n      <td>113</td>\n      <td>[34.024479]</td>\n      <td>[-118.393867]</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>4363</td>\n      <td>13 days 15:34:22.466666666</td>\n      <td>11</td>\n      <td>12</td>\n      <td>13</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n      <td>8</td>\n      <td>9</td>\n      <td>10</td>\n      <td>12</td>\n      <td>7</td>\n      <td>6</td>\n      <td>6</td>\n      <td>[34.03046]</td>\n      <td>[-118.389099]</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>4432</td>\n      <td>10 days 23:02:06.598639455</td>\n      <td>110</td>\n      <td>104</td>\n      <td>98</td>\n      <td>81</td>\n      <td>66</td>\n      <td>99</td>\n      <td>46</td>\n      <td>56</td>\n      <td>64</td>\n      <td>51</td>\n      <td>63</td>\n      <td>60</td>\n      <td>50</td>\n      <td>[34.139568]</td>\n      <td>[-118.362251]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"idle_time\"] = pd.to_timedelta(df[\"idle_time\"])\n",
    "\n",
    "#####################################Important\n",
    "sorted_df = df.sort_values(by=\"idle_time\", ascending=False)\n",
    "sorted_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the station 4403 has an unnormal idle_time, my first idea would be to filter the original data by the station id and plot the idle_time of each trip against the start time of the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:48.358809Z",
     "start_time": "2023-07-22T13:11:48.221785Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################Important\n",
    "full_data = pd.read_csv(\"../Data_Cleanup/outCSV/Metro_Set_DayAndDayTimes.csv\", index_col=0)\n",
    "\n",
    "# Filter the rows for the station with ID 4403\n",
    "station_data = full_data[(full_data['start_station_id'] == 4403) | (full_data['end_station_id'] == 4403)]\n",
    "\n",
    "# Convert the idle_time column to numeric values in days\n",
    "station_data['idle_time'] = pd.to_timedelta(station_data['idle_time']).dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    "# Create a histogram of idle_time values\n",
    "plt.hist(station_data['idle_time'], bins=20)\n",
    "plt.xlabel('Idle Time (days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Idle Time for Station 4403')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Histogramm we can see that we have around 40 rows that has more than 1000 days in idle time.\n",
    "\n",
    "Lets take a better look at those 40 trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:48.698673Z",
     "start_time": "2023-07-22T13:11:48.365329Z"
    }
   },
   "outputs": [],
   "source": [
    "#########Important\n",
    "\n",
    "station_data = full_data[(full_data['start_station_id'] == 4403) | (full_data['end_station_id'] == 4403)]\n",
    "station_data['start_time'] = pd.to_datetime(station_data[\"start_time\"])\n",
    "station_data['end_time'] = pd.to_datetime(station_data[\"end_time\"])\n",
    "\n",
    "# Convert 'idle_time' column to Timedelta\n",
    "station_data['idle_time'] = pd.to_timedelta(station_data['idle_time'])\n",
    "# Filter the rows for the station with ID 4403 and idle_time over 1000 days\n",
    "long_idle_trips = station_data[station_data[\"idle_time\"] > pd.Timedelta(days=1000)]\n",
    "# Sort the trips by end_time in ascending order\n",
    "long_idle_trips = long_idle_trips.sort_values('end_time')\n",
    "\n",
    "# Initialize an empty DataFrame to store the comparison results\n",
    "comparison_results = pd.DataFrame(columns=['Trip', 'End Time', 'Next Start Time'])\n",
    "\n",
    "# Iterate over the rows of the long_idle_trips DataFrame\n",
    "for index, row in long_idle_trips.iterrows():\n",
    "    end_time = row['end_time']\n",
    "    for index, row in station_data.iterrows():\n",
    "        if row[\"start_time\"] > end_time:\n",
    "            next_start_time = row[\"start_time\"]\n",
    "    comparison_results = pd.concat([comparison_results, pd.DataFrame({'Trip': [index], 'End Time': [end_time], 'Next Start Time': [next_start_time]})], ignore_index=True)\n",
    "\n",
    "# Print the comparison results\n",
    "print(comparison_results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems tht there has been a huge break in the usage in this station, let try to find it.\n",
    "\n",
    "Looking at the data we can see that no one used the station between 2020-02-23 15:09:00 and 2022-12-04 14:54:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:48.904882Z",
     "start_time": "2023-07-22T13:11:48.697677Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_df['end_station_lat'] = sorted_df['end_station_lat'].str[1:-1].astype(np.float64)\n",
    "sorted_df['end_station_lon'] = sorted_df['end_station_lon'].str[1:-1].astype(np.float64)\n",
    "\n",
    "\n",
    "\n",
    "# Filter the sorted_df to exclude outliers with more than 30 days of idle time\n",
    "filtered_df = sorted_df[sorted_df['idle_time'] <= pd.Timedelta(days=30)]\n",
    "\n",
    "# Take the top 20 stations with the highest idle time\n",
    "top_20_stations = filtered_df.head(20)\n",
    "\n",
    "# Convert the end_station_id to string\n",
    "top_20_stations[\"end_station_id\"] = top_20_stations[\"end_station_id\"].astype(str)\n",
    "\n",
    "# Plot the vertical bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_20_stations[\"end_station_id\"], top_20_stations[\"idle_time\"].dt.days)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "plt.title(\"Top 20 Stations with Highest Idle Time\")\n",
    "plt.xlabel(\"Station ID\")\n",
    "plt.ylabel(\"Idle Time (Days)\")\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:49.200401Z",
     "start_time": "2023-07-22T13:11:48.907804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take the top 10 stations with the highest idle time\n",
    "bottom_20_stations = filtered_df.tail(20)\n",
    "\n",
    "# Convert the end_station_id to string\n",
    "bottom_20_stations[\"end_station_id\"] = bottom_20_stations[\"end_station_id\"].astype(str)\n",
    "\n",
    "# Plot the vertical bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bottom_20_stations[\"end_station_id\"], bottom_20_stations[\"idle_time\"].dt.total_seconds()/60)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "plt.title(\"Bottom 20 Stations with Lowest Idle Time\")\n",
    "plt.xlabel(\"Station ID\")\n",
    "plt.ylabel(\"Idle Time (Minutes)\")\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To approach the problem methodically. We will sort our data by the average idle_time of the stations. We wil split our data into two halves (top_50_percent and bottom_50_percent). We will look for the average idle_time for each half. the candidate stations (to be either closed or expanded) will be either above the top_avg or below the bottom_avg respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 393 Stations. We will divide them into two halves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:49.766782Z",
     "start_time": "2023-07-22T13:11:49.654690Z"
    }
   },
   "outputs": [],
   "source": [
    "top_50_percent = filtered_df.head(197)\n",
    "bottom_50_percent = filtered_df.tail(196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:11:49.766782Z",
     "start_time": "2023-07-22T13:11:49.697488Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "avg_idle_time_top_50 = top_50_percent[\"idle_time\"].mean()\n",
    "avg_idle_time_bottom_50 = bottom_50_percent[\"idle_time\"].mean()\n",
    "\n",
    "#Our Candidates in the top half\n",
    "over_top_avg_df = top_50_percent[top_50_percent[\"idle_time\"] >= avg_idle_time_top_50]\n",
    "\n",
    "#Our Candidates in the bottom half\n",
    "under_bottom_avg_df = bottom_50_percent[bottom_50_percent[\"idle_time\"] <= avg_idle_time_bottom_50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further filter the candidates we decides to look for the neighboring stations of the candidates. The Radius a station has to be in is 500 m to considered a neighbor. We will take the average of the idle_time of the neighboring stations to see how our candidates is performing regarding its neighbors. if a candidate from the top half has a higher idle_time than the avg_neighbor_idle_time and has at least 2 neighbor, it should be closed. On the other hand if a candidate from the bottom half has a lower idle_time than the avg_neighbor_idle_time and has less than 2 neighbours, it should be expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T13:12:00.668731Z",
     "start_time": "2023-07-22T13:11:50.479300Z"
    }
   },
   "outputs": [],
   "source": [
    "over_top_avg_df[\"neighboring_stations\"] = None\n",
    "over_top_avg_df[\"avg_neighbor_idle_time\"] = None\n",
    "for i, row in over_top_avg_df.iterrows():\n",
    "    station_id = row['end_station_id']\n",
    "    lat = row['end_station_lat']\n",
    "    lon = row['end_station_lon']\n",
    "    center_coords = (lat, lon)\n",
    "    neighbor_idle_time_sum = pd.Timedelta(0)\n",
    "\n",
    "\n",
    "    neighboring_stations = []\n",
    "    for index, sorted_row in filtered_df.iterrows():\n",
    "        station_coords = (sorted_row['end_station_lat'], sorted_row['end_station_lon'])\n",
    "        dist = distance.distance(center_coords, station_coords).meters\n",
    "        \n",
    "        if dist <= 500:\n",
    "            neighboring_stations.append(sorted_row[\"end_station_id\"])\n",
    "            neighbor_idle_time_sum += pd.Timedelta(sorted_row[\"idle_time\"])\n",
    "    over_top_avg_df.at[i, \"neighboring_stations\"] = neighboring_stations\n",
    "    over_top_avg_df.at[i, \"avg_neighbor_idle_time\"] = neighbor_idle_time_sum / len(neighboring_stations)\n",
    "\n",
    "\n",
    "under_bottom_avg_df[\"neighboring_stations\"] = None\n",
    "under_bottom_avg_df[\"avg_neighbor_idle_time\"] = None\n",
    "\n",
    "for i, row in under_bottom_avg_df.iterrows():\n",
    "    station_id = row['end_station_id']\n",
    "    lat = row['end_station_lat']\n",
    "    lon = row['end_station_lon']\n",
    "    center_coords = (lat, lon)\n",
    "    neighbor_idle_time_sum = pd.Timedelta(0)\n",
    "\n",
    "\n",
    "    neighboring_stations = []\n",
    "    for index, sorted_row in filtered_df.iterrows():\n",
    "        station_coords = (sorted_row['end_station_lat'], sorted_row['end_station_lon'])\n",
    "        dist = distance.distance(center_coords, station_coords).meters\n",
    "        \n",
    "        if dist <= 500:\n",
    "            neighboring_stations.append(sorted_row[\"end_station_id\"])\n",
    "            neighbor_idle_time_sum += pd.Timedelta(sorted_row[\"idle_time\"])\n",
    "\n",
    "\n",
    "    under_bottom_avg_df.at[i, \"neighboring_stations\"] = neighboring_stations\n",
    "    under_bottom_avg_df.at[i, \"avg_neighbor_idle_time\"] = neighbor_idle_time_sum / len(neighboring_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_removed = []\n",
    "for i, zeile in over_top_avg_df.iterrows():\n",
    "        if zeile[\"idle_time\"] > zeile[\"avg_neighbor_idle_time\"] and len(zeile[\"neighboring_stations\"]) > 2:\n",
    "            to_be_removed.append(zeile[\"end_station_id\"])\n",
    "\n",
    "\n",
    "to_be_expanded = []\n",
    "for i, zeile in under_bottom_avg_df.iterrows():\n",
    "        if zeile[\"idle_time\"] < zeile[\"avg_neighbor_idle_time\"] and len(zeile[\"neighboring_stations\"]) < 3:\n",
    "            to_be_expanded.append(zeile[\"end_station_id\"])\n",
    "\n",
    "\n",
    "\n",
    "print(to_be_removed)\n",
    "print(len(to_be_removed))\n",
    "print(to_be_expanded)\n",
    "print(len(to_be_expanded))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That would be the list of the Stations that need to either closed or expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latitude and Longitude coordinates of Los Angeles\n",
    "la_coordinates = (34.0522, -118.2437)\n",
    "\n",
    "# Create a folium map centered on Los Angeles\n",
    "map_la = folium.Map(location=la_coordinates, zoom_start=11)\n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    station_id = row['end_station_id']\n",
    "    lat = row['end_station_lat']\n",
    "    lon = row['end_station_lon']\n",
    "    \n",
    "    \n",
    "    if station_id in to_be_expanded:\n",
    "        folium.Marker(location=[lat, lon], tooltip=[str(station_id)], icon = folium.Icon(color=\"green\")).add_to(map_la)\n",
    "    elif station_id in to_be_removed:\n",
    "        folium.Marker(location=[lat, lon], tooltip=[str(station_id)], icon = folium.Icon(color=\"red\")).add_to(map_la)\n",
    "    else:\n",
    "        folium.Marker(location=[lat, lon], tooltip=[str(station_id)]).add_to(map_la)\n",
    "map_la"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
