Index: Merging/Merging Datasets.ipynb
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>{\r\n \"cells\": [\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 7,\r\n   \"metadata\": {},\r\n   \"outputs\": [\r\n    {\r\n     \"name\": \"stderr\",\r\n     \"output_type\": \"stream\",\r\n     \"text\": [\r\n      \"C:\\\\Users\\\\moham\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_2116\\\\460171687.py:5: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\\n\",\r\n      \"  metro_set = pd.read_csv(metro_file, index_col=0)\\n\"\r\n     ]\r\n    }\r\n   ],\r\n   \"source\": [\r\n    \"import pandas as pd\\n\",\r\n    \"from datetime import datetime, timedelta\\n\",\r\n    \"metro_file = '../Data_Cleanup/outCSV/Metro_Set_with_IdleTime.csv'\\n\",\r\n    \"weather_file = \\\"../Data_Cleanup/outCSV/Clean_Weather_Set.csv\\\"\\n\",\r\n    \"metro_set = pd.read_csv(metro_file, index_col=0)\\n\",\r\n    \"weather_set = pd.read_csv(weather_file, index_col=0)\\n\",\r\n    \"\\n\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 8,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"import pandas as pd\\n\",\r\n    \"\\n\",\r\n    \"# Step 1: Convert time columns to a compatible format if necessary\\n\",\r\n    \"\\n\",\r\n    \"metro_set[\\\"start_time\\\"] = pd.to_datetime(metro_set[\\\"start_time\\\"])\\n\",\r\n    \"weather_set[\\\"timestamp\\\"] = pd.to_datetime(weather_set[\\\"timestamp\\\"])\\n\",\r\n    \"\\n\",\r\n    \"# Step 2: Sort both datasets by time\\n\",\r\n    \"\\n\",\r\n    \"Metro_Set = metro_set.sort_values('start_time')\\n\",\r\n    \"Weather_Set = weather_set.sort_values('timestamp')\\n\",\r\n    \"\\n\",\r\n    \"# Step 3: Merge the datasets based on the nearest time\\n\",\r\n    \"\\n\",\r\n    \"merged_set = pd.merge_asof(Metro_Set, Weather_Set, left_on='start_time', right_on='timestamp')\\n\",\r\n    \"\\n\",\r\n    \"# Step 4: Perform a left join and keep all rows from Metro_Set\\n\",\r\n    \"\\n\",\r\n    \"merged_set = pd.merge(Metro_Set, Weather_Set, how='left', left_on='start_time', right_on='timestamp')\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"# The merged_set now contains the Metro_Set with the felt temperature added and missing values filled using forward-fill.\\n\",\r\n    \"\\n\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 12,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"merged_set.drop(\\\"timestamp\\\", axis=1, inplace=True)\\n\",\r\n    \"\\n\",\r\n    \"merged_set[\\\"temperature\\\"].fillna(method=\\\"ffill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"cloud_cover\\\"].fillna(method=\\\"ffill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"cloud_cover_description\\\"].fillna(method=\\\"ffill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"pressure\\\"].fillna(method=\\\"ffill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"windspeed\\\"].fillna(method=\\\"ffill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"precipitation\\\"].fillna(method=\\\"ffill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"felt_temperature\\\"].fillna(method=\\\"ffill\\\", inplace=True)\\n\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 14,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"\\n\",\r\n    \"merged_set[\\\"temperature\\\"].fillna(method=\\\"bfill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"cloud_cover\\\"].fillna(method=\\\"bfill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"cloud_cover_description\\\"].fillna(method=\\\"bfill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"pressure\\\"].fillna(method=\\\"bfill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"windspeed\\\"].fillna(method=\\\"bfill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"precipitation\\\"].fillna(method=\\\"bfill\\\", inplace=True)\\n\",\r\n    \"merged_set[\\\"felt_temperature\\\"].fillna(method=\\\"bfill\\\", inplace=True)\"\r\n   ]\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": 15,\r\n   \"metadata\": {},\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"merged_set.to_csv(\\\"../Data_Cleanup/outCSV/Merged_Set_test1.csv\\\")\"\r\n   ]\r\n  }\r\n ],\r\n \"metadata\": {\r\n  \"kernelspec\": {\r\n   \"display_name\": \"DSML\",\r\n   \"language\": \"python\",\r\n   \"name\": \"python3\"\r\n  },\r\n  \"language_info\": {\r\n   \"codemirror_mode\": {\r\n    \"name\": \"ipython\",\r\n    \"version\": 3\r\n   },\r\n   \"file_extension\": \".py\",\r\n   \"mimetype\": \"text/x-python\",\r\n   \"name\": \"python\",\r\n   \"nbconvert_exporter\": \"python\",\r\n   \"pygments_lexer\": \"ipython3\",\r\n   \"version\": \"3.11.2\"\r\n  },\r\n  \"orig_nbformat\": 4\r\n },\r\n \"nbformat\": 4,\r\n \"nbformat_minor\": 2\r\n}\r\n
===================================================================
diff --git a/Merging/Merging Datasets.ipynb b/Merging/Merging Datasets.ipynb
--- a/Merging/Merging Datasets.ipynb	
+++ b/Merging/Merging Datasets.ipynb	
@@ -2,14 +2,19 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 7,
-   "metadata": {},
+   "execution_count": 1,
+   "metadata": {
+    "ExecuteTime": {
+     "start_time": "2023-07-15T17:19:15.106462Z",
+     "end_time": "2023-07-15T17:19:17.095146Z"
+    }
+   },
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_2116\\460171687.py:5: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
+      "C:\\Users\\yusuf\\AppData\\Local\\Temp\\ipykernel_43856\\2103671802.py:5: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
       "  metro_set = pd.read_csv(metro_file, index_col=0)\n"
      ]
     }
@@ -26,8 +31,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
-   "metadata": {},
+   "execution_count": 2,
+   "metadata": {
+    "ExecuteTime": {
+     "start_time": "2023-07-15T17:19:17.095146Z",
+     "end_time": "2023-07-15T17:19:18.756628Z"
+    }
+   },
    "outputs": [],
    "source": [
     "import pandas as pd\n",
@@ -58,8 +68,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
-   "metadata": {},
+   "execution_count": 3,
+   "metadata": {
+    "ExecuteTime": {
+     "start_time": "2023-07-15T17:19:18.762746Z",
+     "end_time": "2023-07-15T17:19:19.062961Z"
+    }
+   },
    "outputs": [],
    "source": [
     "merged_set.drop(\"timestamp\", axis=1, inplace=True)\n",
@@ -75,8 +90,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
-   "metadata": {},
+   "execution_count": 4,
+   "metadata": {
+    "ExecuteTime": {
+     "start_time": "2023-07-15T17:19:19.062961Z",
+     "end_time": "2023-07-15T17:19:19.237701Z"
+    }
+   },
    "outputs": [],
    "source": [
     "\n",
@@ -91,8 +111,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 15,
-   "metadata": {},
+   "execution_count": 5,
+   "metadata": {
+    "ExecuteTime": {
+     "start_time": "2023-07-15T17:19:19.237701Z",
+     "end_time": "2023-07-15T17:19:32.558950Z"
+    }
+   },
    "outputs": [],
    "source": [
     "merged_set.to_csv(\"../Data_Cleanup/outCSV/Merged_Set_test1.csv\")"
